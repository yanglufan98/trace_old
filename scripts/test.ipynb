{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from tbsim.configs.scene_edit_config import SceneEditingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {0: 'a'}\n",
    "key = list(a.keys())[0]  # Convert keys() view to list and get first key\n",
    "a[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'key'"
     ]
    }
   ],
   "source": [
    "a.key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(a.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args & configs\n",
    "cfg = SceneEditingConfig()\n",
    "config_file = '/local-scratch2/lufan/traceMR/configs/eval/orca/target_pos.json'\n",
    "eval_class = 'Diffuser'\n",
    "policy_ckpt_dir = '/local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed'\n",
    "policy_ckpt_key = 'iter40000'\n",
    "results_root_dir = '/local-scratch2/lufan/traceMR/out/orca_mixed_out'\n",
    "num_scenes_per_batch = 1\n",
    "render = False\n",
    "render_img = True\n",
    "render_size = 400\n",
    "render_px_per_m = 12.0\n",
    "seed = None\n",
    "prefix = None\n",
    "ground_truth = False\n",
    "editing_source = 'heuristic'\n",
    "\n",
    "if config_file is not None:\n",
    "    external_cfg = json.load(open(config_file, \"r\"))\n",
    "    cfg.update(**external_cfg)\n",
    "\n",
    "if eval_class is not None:\n",
    "    cfg.eval_class = eval_class\n",
    "\n",
    "if policy_ckpt_dir is not None:\n",
    "    assert policy_ckpt_key is not None, \"Please specify a key to look for the checkpoint, e.g., 'iter50000'\"\n",
    "    cfg.ckpt.policy.ckpt_dir = policy_ckpt_dir\n",
    "    cfg.ckpt.policy.ckpt_key = policy_ckpt_key\n",
    "\n",
    "if num_scenes_per_batch is not None:\n",
    "    cfg.num_scenes_per_batch = num_scenes_per_batch\n",
    "\n",
    "if cfg.name is None:\n",
    "    cfg.name = cfg.eval_class\n",
    "\n",
    "if prefix is not None:\n",
    "    cfg.name = prefix + cfg.name\n",
    "\n",
    "if seed is not None:\n",
    "    cfg.seed = seed\n",
    "if results_root_dir is not None:\n",
    "    cfg.results_dir = os.path.join(results_root_dir, cfg.name)\n",
    "else:\n",
    "    cfg.results_dir = os.path.join(cfg.results_dir, cfg.name)\n",
    "assert cfg.env == \"trajdata\", \"trajdata is the only supported environment\"\n",
    "if editing_source is not None:\n",
    "    cfg.edits.editing_source = editing_source\n",
    "if not isinstance(cfg.edits.editing_source, list):\n",
    "    cfg.edits.editing_source = [cfg.edits.editing_source]\n",
    "\n",
    "cfg.experience_hdf5_path = os.path.join(cfg.results_dir, \"data.hdf5\")\n",
    "\n",
    "for k in cfg[cfg.env]:  # copy env-specific config to the global-level\n",
    "    cfg[k] = cfg[cfg.env][k]\n",
    "cfg.pop(\"trajdata\")\n",
    "\n",
    "render_cfg = {\n",
    "    'size' : render_size,\n",
    "    'px_per_m' : render_px_per_m,\n",
    "}\n",
    "\n",
    "cfg.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"orca_map_open_loop_target_pos\",\n",
      "    \"env\": \"trajdata\",\n",
      "    \"dataset_path\": null,\n",
      "    \"eval_class\": \"Diffuser\",\n",
      "    \"seed\": 0,\n",
      "    \"num_scenes_per_batch\": 1,\n",
      "    \"num_scenes_to_evaluate\": 100,\n",
      "    \"num_episode_repeats\": 1,\n",
      "    \"start_frame_index_each_episode\": null,\n",
      "    \"seed_each_episode\": null,\n",
      "    \"ego_only\": false,\n",
      "    \"ckpt_root_dir\": \"checkpoints/\",\n",
      "    \"experience_hdf5_path\": \"/local-scratch2/lufan/traceMR/out/orca_mixed_out/orca_map_open_loop_target_pos/data.hdf5\",\n",
      "    \"results_dir\": \"/local-scratch2/lufan/traceMR/out/orca_mixed_out/orca_map_open_loop_target_pos\",\n",
      "    \"ckpt\": {\n",
      "        \"policy\": {\n",
      "            \"ckpt_dir\": \"/local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed\",\n",
      "            \"ckpt_key\": \"iter40000\",\n",
      "            \"ngc_job_id\": null\n",
      "        }\n",
      "    },\n",
      "    \"policy\": {\n",
      "        \"num_action_samples\": 20,\n",
      "        \"guide_as_filter_only\": false,\n",
      "        \"guide_with_gt\": false,\n",
      "        \"class_free_guide_w\": 0.0,\n",
      "        \"guide_clean\": true\n",
      "    },\n",
      "    \"metrics\": {\n",
      "        \"compute_analytical_metrics\": true\n",
      "    },\n",
      "    \"edits\": {\n",
      "        \"editing_source\": [\n",
      "            \"heuristic\"\n",
      "        ],\n",
      "        \"guidance_config\": [],\n",
      "        \"heuristic_config\": [\n",
      "            {\n",
      "                \"name\": \"target_pos\",\n",
      "                \"weight\": 30000.0,\n",
      "                \"params\": {\n",
      "                    \"target_time\": 40\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"constraint_config\": []\n",
      "    },\n",
      "    \"agent_eval_class\": null,\n",
      "    \"trajdata_cache_location\": \"~/.unified_data_cache\",\n",
      "    \"trajdata_rebuild_cache\": false,\n",
      "    \"trajdata_source_test\": [\n",
      "        \"orca_maps-test\"\n",
      "    ],\n",
      "    \"trajdata_data_dirs\": {\n",
      "        \"orca_maps\": \"./datasets/orca_sim\",\n",
      "        \"orca_no_maps\": \"./datasets/orca_sim\"\n",
      "    },\n",
      "    \"eval_scenes\": [\n",
      "        0,\n",
      "        1,\n",
      "        2,\n",
      "        3,\n",
      "        4,\n",
      "        5,\n",
      "        6,\n",
      "        7,\n",
      "        8,\n",
      "        9,\n",
      "        10,\n",
      "        11,\n",
      "        12,\n",
      "        13,\n",
      "        14,\n",
      "        15,\n",
      "        16,\n",
      "        17,\n",
      "        18,\n",
      "        19,\n",
      "        20,\n",
      "        21,\n",
      "        22,\n",
      "        23,\n",
      "        24,\n",
      "        25,\n",
      "        26,\n",
      "        27,\n",
      "        28,\n",
      "        29,\n",
      "        30,\n",
      "        31,\n",
      "        32,\n",
      "        33,\n",
      "        34,\n",
      "        35,\n",
      "        36,\n",
      "        37,\n",
      "        38,\n",
      "        39,\n",
      "        40,\n",
      "        41,\n",
      "        42,\n",
      "        43,\n",
      "        44,\n",
      "        45,\n",
      "        46,\n",
      "        47,\n",
      "        48,\n",
      "        49,\n",
      "        50,\n",
      "        51,\n",
      "        52,\n",
      "        53,\n",
      "        54,\n",
      "        55,\n",
      "        56,\n",
      "        57,\n",
      "        58,\n",
      "        59,\n",
      "        60,\n",
      "        61,\n",
      "        62,\n",
      "        63,\n",
      "        64,\n",
      "        65,\n",
      "        66,\n",
      "        67,\n",
      "        68,\n",
      "        69,\n",
      "        70,\n",
      "        71,\n",
      "        72,\n",
      "        73,\n",
      "        74,\n",
      "        75,\n",
      "        76,\n",
      "        77,\n",
      "        78,\n",
      "        79,\n",
      "        80,\n",
      "        81,\n",
      "        82,\n",
      "        83,\n",
      "        84,\n",
      "        85,\n",
      "        86,\n",
      "        87,\n",
      "        88,\n",
      "        89,\n",
      "        90,\n",
      "        91,\n",
      "        92,\n",
      "        93,\n",
      "        94,\n",
      "        95,\n",
      "        96,\n",
      "        97,\n",
      "        98,\n",
      "        99\n",
      "    ],\n",
      "    \"n_step_action\": 50,\n",
      "    \"num_simulation_steps\": 50,\n",
      "    \"skip_first_n\": 0,\n",
      "    \"num_sim_per_scene\": 1\n",
      "}\n",
      "saving results to /local-scratch2/lufan/traceMR/out/orca_mixed_out/orca_map_open_loop_target_pos\n"
     ]
    }
   ],
   "source": [
    "# basic setup, before init policy\n",
    "from tbsim.utils.trajdata_utils import set_global_trajdata_batch_env\n",
    "\"\"\"\n",
    "run_scene_editor(\n",
    "    cfg,\n",
    "    save_cfg=True,\n",
    "    data_to_disk=True,\n",
    "    render_to_video=args.render,\n",
    "    render_to_img=args.render_img,\n",
    "    render_cfg=render_cfg,\n",
    "    use_gt=args.ground_truth,\n",
    ")\n",
    "\"\"\"\n",
    "eval_cfg = cfg\n",
    "save_cfg = True\n",
    "data_to_disk = True\n",
    "render_to_video = render\n",
    "render_to_img = render_img\n",
    "render_cfg = render_cfg\n",
    "use_gt = ground_truth\n",
    "\n",
    "set_global_trajdata_batch_env(eval_cfg.trajdata_source_test[0])\n",
    "print(eval_cfg)\n",
    "# for reproducibility\n",
    "np.random.seed(eval_cfg.seed)\n",
    "random.seed(eval_cfg.seed)\n",
    "torch.manual_seed(eval_cfg.seed)\n",
    "torch.cuda.manual_seed(eval_cfg.seed)\n",
    "\n",
    "# basic setup\n",
    "print('saving results to {}'.format(eval_cfg.results_dir))\n",
    "os.makedirs(eval_cfg.results_dir, exist_ok=True)\n",
    "if render_to_video:\n",
    "    os.makedirs(os.path.join(eval_cfg.results_dir, \"videos/\"), exist_ok=True)\n",
    "if render_to_video or render_to_img:\n",
    "    os.makedirs(os.path.join(eval_cfg.results_dir, \"viz/\"), exist_ok=True)\n",
    "if save_cfg:\n",
    "    json.dump(eval_cfg, open(os.path.join(eval_cfg.results_dir, \"config.json\"), \"w+\"))\n",
    "if data_to_disk and os.path.exists(eval_cfg.experience_hdf5_path):\n",
    "    os.remove(eval_cfg.experience_hdf5_path)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_composers = importlib.import_module(\"tbsim.evaluation.policy_composers\")\n",
    "composer_class = getattr(policy_composers, eval_cfg.eval_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed/iter40000.ckpt\n",
      "Config path: /local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIFFUSER: Dropping map input conditioning with p = 0.100000 during training...\n",
      "DIFFUSER: Dropping neighbor traj input conditioning with p = 0.100000 during training...\n",
      "[ models/temporal ] Channel dimensions: [(38, 64), (64, 128), (128, 256)]\n",
      "DIFFUSER: using EMA... val and get_action will use ema model\n"
     ]
    }
   ],
   "source": [
    "# create policy and rollout wrapper\n",
    "policy_composers = importlib.import_module(\"tbsim.evaluation.policy_composers\")\n",
    "composer_class = getattr(policy_composers, eval_cfg.eval_class)\n",
    "composer = composer_class(eval_cfg, device)\n",
    "policy, exp_config = composer.get_policy()\n",
    "policy_model = policy.model\n",
    "\n",
    "# if use_gt is ignored here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines cfg for rasterizing agents\n",
    "def set_global_trajdata_batch_raster_cfg(raster_cfg):\n",
    "    global BATCH_RASTER_CFG\n",
    "    assert \"include_hist\" in raster_cfg\n",
    "    assert \"pixel_size\" in raster_cfg\n",
    "    assert \"raster_size\" in raster_cfg\n",
    "    assert \"ego_center\" in raster_cfg\n",
    "    assert \"num_sem_layers\" in raster_cfg\n",
    "    assert \"no_map_fill_value\" in raster_cfg\n",
    "    assert \"drivable_layers\" in raster_cfg\n",
    "    BATCH_RASTER_CFG = raster_cfg\n",
    "\n",
    "set_global_trajdata_batch_raster_cfg(exp_config.env.rasterizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control the full scene with same policy\n",
    "from tbsim.policies.common import Action, Plan, RolloutAction\n",
    "class RolloutWrapper(object):\n",
    "    \"\"\"A wrapper policy that can (optionally) control both ego and other agents in a scene\"\"\"\n",
    "\n",
    "    def __init__(self, ego_policy=None, agents_policy=None, pass_agent_obs=True):\n",
    "        self.device = ego_policy.device if agents_policy is None else agents_policy.device\n",
    "        self.ego_policy = ego_policy\n",
    "        self.agents_policy = agents_policy\n",
    "        self.pass_agent_obs = pass_agent_obs\n",
    "\n",
    "    def eval(self):\n",
    "        self.ego_policy.eval()\n",
    "        self.agents_policy.eval()\n",
    "\n",
    "    def get_action(self, obs, step_index) -> RolloutAction:\n",
    "        ego_action = None\n",
    "        ego_action_info = None\n",
    "        agents_action = None\n",
    "        agents_action_info = None\n",
    "        if self.ego_policy is not None:\n",
    "            assert obs[\"ego\"] is not None\n",
    "            with torch.no_grad():\n",
    "                if self.pass_agent_obs:\n",
    "                    ego_action, ego_action_info = self.ego_policy.get_action(\n",
    "                        obs[\"ego\"], step_index = step_index,agent_obs = obs[\"agents\"])\n",
    "                else:\n",
    "                    ego_action, ego_action_info = self.ego_policy.get_action(\n",
    "                        obs[\"ego\"], step_index = step_index)\n",
    "        if self.agents_policy is not None:\n",
    "            assert obs[\"agents\"] is not None\n",
    "            with torch.no_grad():\n",
    "                agents_action, agents_action_info = self.agents_policy.get_action(\n",
    "                    obs[\"agents\"], step_index = step_index)\n",
    "        return RolloutAction(ego_action, ego_action_info, agents_action, agents_action_info)\n",
    "\n",
    "rollout_policy = RolloutWrapper(agents_policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"diffuser\",\n",
      "    \"eval_class\": \"Diffuser\",\n",
      "    \"map_encoder_model_arch\": \"resnet18\",\n",
      "    \"diffuser_model_arch\": \"TemporalMapUnet\",\n",
      "    \"rasterized_map\": true,\n",
      "    \"use_map_feat_global\": false,\n",
      "    \"use_map_feat_grid\": true,\n",
      "    \"base_dim\": 32,\n",
      "    \"horizon\": 52,\n",
      "    \"n_diffusion_steps\": 100,\n",
      "    \"action_weight\": 1,\n",
      "    \"loss_discount\": 1,\n",
      "    \"dim_mults\": [\n",
      "        2,\n",
      "        4,\n",
      "        8\n",
      "    ],\n",
      "    \"loss_type\": \"l2\",\n",
      "    \"use_ema\": true,\n",
      "    \"ema_step\": 1,\n",
      "    \"ema_decay\": 0.995,\n",
      "    \"ema_start_step\": 2000,\n",
      "    \"diffuser_input_mode\": \"state_and_action\",\n",
      "    \"conditioning_drop_map_p\": 0.1,\n",
      "    \"conditioning_drop_neighbor_p\": 0.1,\n",
      "    \"conditioning_drop_fill\": 0.5,\n",
      "    \"cond_feat_dim\": 256,\n",
      "    \"map_feature_dim\": 256,\n",
      "    \"map_grid_feature_dim\": 32,\n",
      "    \"history_feature_dim\": 128,\n",
      "    \"history_num_frames\": 30,\n",
      "    \"history_num_frames_ego\": 30,\n",
      "    \"history_num_frames_agents\": 30,\n",
      "    \"future_num_frames\": 52,\n",
      "    \"step_time\": 0.1,\n",
      "    \"dynamics\": {\n",
      "        \"type\": \"Unicycle\",\n",
      "        \"max_steer\": 0.5,\n",
      "        \"max_yawvel\": 6.283185307179586,\n",
      "        \"acce_bound\": [\n",
      "            -10,\n",
      "            8\n",
      "        ],\n",
      "        \"ddh_bound\": [\n",
      "            -6.283185307179586,\n",
      "            6.283185307179586\n",
      "        ],\n",
      "        \"max_speed\": 40.0\n",
      "    },\n",
      "    \"loss_weights\": {\n",
      "        \"diffusion_loss\": 1.0\n",
      "    },\n",
      "    \"optim_params\": {\n",
      "        \"policy\": {\n",
      "            \"learning_rate\": {\n",
      "                \"initial\": 0.0002,\n",
      "                \"decay_factor\": 0.1,\n",
      "                \"epoch_schedule\": []\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"diffuser\": {\n",
      "        \"num_eval_samples\": 10\n",
      "    },\n",
      "    \"diffuser_norm_info\": [\n",
      "        [\n",
      "            -3.538049,\n",
      "            0.004175,\n",
      "            -1.360894,\n",
      "            0.001894,\n",
      "            0.015233,\n",
      "            0.000562\n",
      "        ],\n",
      "        [\n",
      "            2.304491,\n",
      "            0.462847,\n",
      "            0.426683,\n",
      "            0.19193,\n",
      "            0.255089,\n",
      "            0.175583\n",
      "        ]\n",
      "    ],\n",
      "    \"agent_hist_norm_info\": [\n",
      "        [\n",
      "            2.07473,\n",
      "            -0.000102,\n",
      "            -1.401319,\n",
      "            0.0,\n",
      "            0.0\n",
      "        ],\n",
      "        [\n",
      "            1.376582,\n",
      "            0.214366,\n",
      "            0.369064,\n",
      "            1.0,\n",
      "            1.0\n",
      "        ]\n",
      "    ],\n",
      "    \"neighbor_hist_norm_info\": [\n",
      "        [\n",
      "            -2.804952,\n",
      "            -0.037075,\n",
      "            -0.544995,\n",
      "            0.0,\n",
      "            0.0\n",
      "        ],\n",
      "        [\n",
      "            6.161589,\n",
      "            6.486891,\n",
      "            0.771583,\n",
      "            1.0,\n",
      "            1.0\n",
      "        ]\n",
      "    ],\n",
      "    \"rasterized_history\": false,\n",
      "    \"diffusor_loss_weights\": null,\n",
      "    \"predict_epsilon\": false,\n",
      "    \"clip_denoised\": false,\n",
      "    \"diffuser_building_block\": \"concat\",\n",
      "    \"use_reconstructed_state\": false,\n",
      "    \"curr_state_feat_dim\": 64,\n",
      "    \"render_ego_history\": false,\n",
      "    \"decoder\": {\n",
      "        \"layer_dims\": [],\n",
      "        \"state_as_input\": true\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(exp_config.algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for matched scene tags: ['test-orca_maps']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 100/100 [00:00<00:00, 15472.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 100/100 [00:00<00:00, 1920.60it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 100/100 [00:00<00:00, 24621.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"trajdata\",\n",
      "    \"data_generation_params\": {\n",
      "        \"trajdata_centric\": \"agent\",\n",
      "        \"trajdata_only_types\": [\n",
      "            \"pedestrian\"\n",
      "        ],\n",
      "        \"trajdata_predict_types\": [\n",
      "            \"pedestrian\"\n",
      "        ],\n",
      "        \"trajdata_scene_desc_contains\": null,\n",
      "        \"trajdata_incl_map\": true,\n",
      "        \"trajdata_max_agents_distance\": 15.0,\n",
      "        \"trajdata_standardize_data\": true\n",
      "    },\n",
      "    \"rasterizer\": {\n",
      "        \"include_hist\": false,\n",
      "        \"num_sem_layers\": 2,\n",
      "        \"drivable_layers\": [\n",
      "            0\n",
      "        ],\n",
      "        \"rgb_idx_groups\": [\n",
      "            [\n",
      "                1\n",
      "            ],\n",
      "            [\n",
      "                0\n",
      "            ],\n",
      "            [\n",
      "                1\n",
      "            ]\n",
      "        ],\n",
      "        \"raster_size\": 224,\n",
      "        \"pixel_size\": 0.08333333333333333,\n",
      "        \"ego_center\": [\n",
      "            -0.5,\n",
      "            0.0\n",
      "        ],\n",
      "        \"no_map_fill_value\": 0.5\n",
      "    },\n",
      "    \"simulation\": {\n",
      "        \"num_simulation_steps\": 50,\n",
      "        \"start_frame_index\": 31\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create env\n",
    "from tbsim.evaluation.env_builders import EnvUnifiedBuilder\n",
    "env_builder = EnvUnifiedBuilder(eval_config=eval_cfg, exp_config=exp_config, device=device)\n",
    "env = env_builder.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up heuristic guidance config\n",
    "heuristic_config = None\n",
    "if \"heuristic\" in eval_cfg.edits.editing_source:\n",
    "    if eval_cfg.edits.heuristic_config is not None:\n",
    "        heuristic_config = eval_cfg.edits.heuristic_config\n",
    "    else:\n",
    "        heuristic_config = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation for render\n",
    "render_rasterizer = None\n",
    "if render_to_video or render_to_img:\n",
    "    from tbsim.utils.viz_utils import get_trajdata_renderer\n",
    "    # initialize rasterizer once for all scenes\n",
    "    render_rasterizer = get_trajdata_renderer(eval_cfg.trajdata_source_test,\n",
    "                                                eval_cfg.trajdata_data_dirs,\n",
    "                                                raster_size=render_cfg['size'],\n",
    "                                                px_per_m=render_cfg['px_per_m'],\n",
    "                                                rebuild_maps=False,\n",
    "                                                cache_location=eval_cfg.trajdata_cache_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(scene_indices)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# check to make sure all the scenes are valid at starting step\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m scenes_valid \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscene_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscene_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_frame_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m scene_indices \u001b[38;5;241m=\u001b[39m [si \u001b[38;5;28;01mfor\u001b[39;00m si, sval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(scene_indices, scenes_valid) \u001b[38;5;28;01mif\u001b[39;00m sval]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scene_indices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/local-scratch2/lufan/traceMR/tbsim/envs/env_trajdata.py:186\u001b[0m, in \u001b[0;36mEnvUnifiedSimulation.reset\u001b[0;34m(self, scene_indices, start_frame_index)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    185\u001b[0m obs \u001b[38;5;241m=\u001b[39m sim_scene\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disable_offroad_agents\u001b[49m\u001b[43m(\u001b[49m\u001b[43msim_scene\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_scenes\u001b[38;5;241m.\u001b[39mappend(sim_scene)\n\u001b[1;32m    188\u001b[0m scenes_valid\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/local-scratch2/lufan/traceMR/tbsim/envs/env_trajdata.py:120\u001b[0m, in \u001b[0;36mEnvUnifiedSimulation._disable_offroad_agents\u001b[0;34m(self, scene)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_disable_offroad_agents\u001b[39m(\u001b[38;5;28mself\u001b[39m, scene):\n\u001b[1;32m    119\u001b[0m     obs \u001b[38;5;241m=\u001b[39m scene\u001b[38;5;241m.\u001b[39mget_obs()\n\u001b[0;32m--> 120\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[43mparse_trajdata_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaps\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         obs_maps \u001b[38;5;241m=\u001b[39m verify_map(obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/tracer/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/local-scratch2/lufan/traceMR/tbsim/utils/trajdata_utils.py:312\u001b[0m, in \u001b[0;36mparse_trajdata_batch\u001b[0;34m(batch, overwrite_nan)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently only support agent-centric trajdata, not scene-centric\u001b[39m\u001b[38;5;124m\"\u001b[39m)        \n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# agent centric\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[43mparse_node_centric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(batch)\n\u001b[1;32m    315\u001b[0m batch\u001b[38;5;241m.\u001b[39mupdate(d)\n",
      "File \u001b[0;32m/local-scratch2/lufan/traceMR/tbsim/utils/trajdata_utils.py:192\u001b[0m, in \u001b[0;36mparse_node_centric\u001b[0;34m(batch, overwrite_nan)\u001b[0m\n\u001b[1;32m    189\u001b[0m world_from_agents \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39minverse(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magents_from_world_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    191\u001b[0m raster_cfg \u001b[38;5;241m=\u001b[39m BATCH_RASTER_CFG\n\u001b[0;32m--> 192\u001b[0m map_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[43mraster_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpixel_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# convert to pixels/meter\u001b[39;00m\n\u001b[1;32m    193\u001b[0m h \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m=\u001b[39m raster_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraster_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    194\u001b[0m ego_cent \u001b[38;5;241m=\u001b[39m raster_cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mego_center\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "result_stats = None\n",
    "scene_i = 0\n",
    "eval_scenes = eval_cfg.eval_scenes\n",
    "\n",
    "# while scene_i < eval_cfg.num_scenes_to_evaluate:\n",
    "scene_indices = eval_scenes[scene_i: scene_i + eval_cfg.num_scenes_per_batch]\n",
    "scene_i += eval_cfg.num_scenes_per_batch\n",
    "print(scene_indices)\n",
    "# check to make sure all the scenes are valid at starting step\n",
    "scenes_valid = env.reset(scene_indices=scene_indices, start_frame_index=None)\n",
    "scene_indices = [si for si, sval in zip(scene_indices, scenes_valid) if sval]\n",
    "if len(scene_indices) == 0:\n",
    "    torch.cuda.empty_cache()\n",
    "    # continue\n",
    "\n",
    "# if requested, split each scene up into multiple simulations\n",
    "start_frame_index = [[exp_config.algo.history_num_frames+1]] * len(scene_indices)\n",
    "if eval_cfg.num_sim_per_scene > 1:\n",
    "    start_frame_index = []\n",
    "    for si in range(len(scene_indices)):\n",
    "        cur_scene = env._current_scenes[si].scene\n",
    "        sframe = exp_config.algo.history_num_frames+1\n",
    "        # want to make sure there's GT for the full rollout\n",
    "        eframe = cur_scene.length_timesteps - eval_cfg.num_simulation_steps\n",
    "        scene_frame_inds = np.linspace(sframe, eframe, num=eval_cfg.num_sim_per_scene, dtype=int).tolist()\n",
    "        start_frame_index.append(scene_frame_inds)\n",
    "\n",
    "print('Starting frames in current scenes:')\n",
    "print(start_frame_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ei in range(eval_cfg.num_sim_per_scene):\n",
    "    guidance_config = None\n",
    "\n",
    "    cur_start_frames = [scene_start[ei] for scene_start in start_frame_index]\n",
    "    # double check all scenes are valid at the current start step\n",
    "    scenes_valid = env.reset(scene_indices=scene_indices, start_frame_index=cur_start_frames)\n",
    "    sim_scene_indices = [si for si, sval in zip(scene_indices, scenes_valid) if sval]\n",
    "    sim_start_frames = [sframe for sframe, sval in zip(cur_start_frames, scenes_valid) if sval]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'target_pos', 'weight': 30000.0, 'params': {'target_time': 40}}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heuristic']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval_cfg.edits.editing_source ['heuristic']\n",
    "from tbsim.utils.scene_edit_utils import compute_heuristic_guidance\n",
    "\n",
    "\n",
    "heuristic_guidance_cfg = compute_heuristic_guidance(heuristic_config,\n",
    "                                                    env,\n",
    "                                                    sim_scene_indices,\n",
    "                                                    sim_start_frames)\n",
    "if len(heuristic_config) > 0: # means that the compute_heuristic_guiance exist\n",
    "    valid_scene_inds = []\n",
    "    for sci, sc_cfg in enumerate(heuristic_guidance_cfg):\n",
    "        if len(sc_cfg) > 0:\n",
    "            valid_scene_inds.append(sci)\n",
    "    \n",
    "    # collect only valid scenes under the given heuristic config\n",
    "    heuristic_guidance_cfg = [heuristic_guidance_cfg[vi] for vi in valid_scene_inds]\n",
    "    print(\"what do we get from the heuristic_guidance_cfg[vi]?\")\n",
    "    import pdb; pdb.set_trace()\n",
    "    sim_scene_indices = [sim_scene_indices[vi] for vi in valid_scene_inds]\n",
    "    sim_start_frames = [sim_start_frames[vi] for vi in valid_scene_inds]\n",
    "    # skip if no valid\n",
    "\n",
    "guidance_config = merge_guidance_configs(guidance_config, heuristic_guidance_cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats, info = guided_rollout(env, rollout_policy, policy_model, n_step_action=eval_cfg.n_step_action,\n",
    "                             guidance_config=guidance_config,\n",
    "                             scene_indices=sim_scene_indices,\n",
    "                             obs_to_torch=True,\n",
    "                             horizon=eval_cfg.num_simulation_steps,\n",
    "                             use_gt=use_gt,\n",
    "                             start_frames=sim_start_frames,\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info[\"scene_index\"])\n",
    "print(sim_start_frames)\n",
    "pprint(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with tbsim_env\n",
    "create a new env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from tbsim.configs.scene_edit_config import SceneEditingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args & configs\n",
    "cfg = SceneEditingConfig()\n",
    "config_file = '/local-scratch2/lufan/traceMR/configs/eval/orca/target_pos.json'\n",
    "eval_class = 'Diffuser'\n",
    "policy_ckpt_dir = '/local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed'\n",
    "policy_ckpt_key = 'iter40000'\n",
    "results_root_dir = '/local-scratch2/lufan/traceMR/out/orca_mixed_out'\n",
    "num_scenes_per_batch = 1\n",
    "render = False\n",
    "render_img = True\n",
    "render_size = 400\n",
    "render_px_per_m = 12.0\n",
    "seed = None\n",
    "prefix = None\n",
    "ground_truth = False\n",
    "editing_source = 'heuristic'\n",
    "\n",
    "if config_file is not None:\n",
    "    external_cfg = json.load(open(config_file, \"r\"))\n",
    "    cfg.update(**external_cfg)\n",
    "\n",
    "if eval_class is not None:\n",
    "    cfg.eval_class = eval_class\n",
    "\n",
    "if policy_ckpt_dir is not None:\n",
    "    assert policy_ckpt_key is not None, \"Please specify a key to look for the checkpoint, e.g., 'iter50000'\"\n",
    "    cfg.ckpt.policy.ckpt_dir = policy_ckpt_dir\n",
    "    cfg.ckpt.policy.ckpt_key = policy_ckpt_key\n",
    "\n",
    "if num_scenes_per_batch is not None:\n",
    "    cfg.num_scenes_per_batch = num_scenes_per_batch\n",
    "\n",
    "if cfg.name is None:\n",
    "    cfg.name = cfg.eval_class\n",
    "\n",
    "if prefix is not None:\n",
    "    cfg.name = prefix + cfg.name\n",
    "\n",
    "if seed is not None:\n",
    "    cfg.seed = seed\n",
    "if results_root_dir is not None:\n",
    "    cfg.results_dir = os.path.join(results_root_dir, cfg.name)\n",
    "else:\n",
    "    cfg.results_dir = os.path.join(cfg.results_dir, cfg.name)\n",
    "assert cfg.env == \"trajdata\", \"trajdata is the only supported environment\"\n",
    "if editing_source is not None:\n",
    "    cfg.edits.editing_source = editing_source\n",
    "if not isinstance(cfg.edits.editing_source, list):\n",
    "    cfg.edits.editing_source = [cfg.edits.editing_source]\n",
    "\n",
    "cfg.experience_hdf5_path = os.path.join(cfg.results_dir, \"data.hdf5\")\n",
    "\n",
    "for k in cfg[cfg.env]:  # copy env-specific config to the global-level\n",
    "    cfg[k] = cfg[cfg.env][k]\n",
    "cfg.pop(\"trajdata\")\n",
    "\n",
    "render_cfg = {\n",
    "    'size' : render_size,\n",
    "    'px_per_m' : render_px_per_m,\n",
    "}\n",
    "\n",
    "cfg.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed/iter40000.ckpt\n",
      "Config path: /local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed/config.json\n",
      "DIFFUSER: Dropping map input conditioning with p = 0.100000 during training...\n",
      "DIFFUSER: Dropping neighbor traj input conditioning with p = 0.100000 during training...\n",
      "[ models/temporal ] Channel dimensions: [(38, 64), (64, 128), (128, 256)]\n",
      "DIFFUSER: using EMA... val and get_action will use ema model\n",
      "Loading data for matched scene tags: ['test-orca_maps']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Agent Data (Serially): 100%|██████████| 100/100 [00:00<00:00, 61079.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 scenes in the scene index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Agent Data Index (Serially): 100%|██████████| 100/100 [00:00<00:00, 6074.04it/s]\n",
      "Structuring Agent Data Index: 100%|██████████| 100/100 [00:00<00:00, 64736.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"trajdata\",\n",
      "    \"data_generation_params\": {\n",
      "        \"trajdata_centric\": \"agent\",\n",
      "        \"trajdata_only_types\": [\n",
      "            \"pedestrian\"\n",
      "        ],\n",
      "        \"trajdata_predict_types\": [\n",
      "            \"pedestrian\"\n",
      "        ],\n",
      "        \"trajdata_scene_desc_contains\": null,\n",
      "        \"trajdata_incl_map\": true,\n",
      "        \"trajdata_max_agents_distance\": 15.0,\n",
      "        \"trajdata_standardize_data\": true\n",
      "    },\n",
      "    \"rasterizer\": {\n",
      "        \"include_hist\": false,\n",
      "        \"num_sem_layers\": 2,\n",
      "        \"drivable_layers\": [\n",
      "            0\n",
      "        ],\n",
      "        \"rgb_idx_groups\": [\n",
      "            [\n",
      "                1\n",
      "            ],\n",
      "            [\n",
      "                0\n",
      "            ],\n",
      "            [\n",
      "                1\n",
      "            ]\n",
      "        ],\n",
      "        \"raster_size\": 224,\n",
      "        \"pixel_size\": 0.08333333333333333,\n",
      "        \"ego_center\": [\n",
      "            -0.5,\n",
      "            0.0\n",
      "        ],\n",
      "        \"no_map_fill_value\": 0.5\n",
      "    },\n",
      "    \"simulation\": {\n",
      "        \"num_simulation_steps\": 50,\n",
      "        \"start_frame_index\": 31\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tbsim.evaluation.env_builders import EnvUnifiedBuilder\n",
    "from tbsim.utils.trajdata_utils import set_global_trajdata_batch_raster_cfg\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy_composers = importlib.import_module(\"tbsim.evaluation.policy_composers\")\n",
    "composer_class = getattr(policy_composers, eval_cfg.eval_class)\n",
    "composer = composer_class(eval_cfg, device)\n",
    "policy, exp_config = composer.get_policy()\n",
    "eval_cfg = cfg\n",
    "exp_config = exp_config\n",
    "device = device\n",
    "env_builder = EnvUnifiedBuilder(eval_config=eval_cfg, exp_config=exp_config, device=device)\n",
    "env = env_builder.get_env()\n",
    "set_global_trajdata_batch_raster_cfg(exp_config.env.rasterizer)\n",
    "env.reset()\n",
    "obs = env.get_observation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(200):\n",
    "    env.reset()\n",
    "    obs=env.get_observation()\n",
    "    if 'ego' in obs.keys():\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['agents'])\n",
      "dict_keys(['data_idx', 'dt', 'agent_type', 'curr_agent_state', 'agent_hist', 'agent_hist_extent', 'agent_hist_len', 'agent_fut', 'agent_fut_extent', 'agent_fut_len', 'num_neigh', 'neigh_types', 'neigh_hist', 'neigh_hist_extents', 'neigh_hist_len', 'neigh_fut', 'neigh_fut_extents', 'neigh_fut_len', 'robot_fut_len', 'maps', 'maps_resolution', 'rasters_from_world_tf', 'agents_from_world_tf', 'extras', 'image', 'drivable_map', 'target_positions', 'target_yaws', 'target_availabilities', 'history_positions', 'history_yaws', 'history_speeds', 'history_availabilities', 'curr_speed', 'centroid', 'yaw', 'type', 'extent', 'raster_from_agent', 'agent_from_raster', 'raster_from_world', 'agent_from_world', 'world_from_agent', 'all_other_agents_history_positions', 'all_other_agents_history_yaws', 'all_other_agents_history_speeds', 'all_other_agents_history_availabilities', 'all_other_agents_history_availability', 'all_other_agents_curr_speed', 'all_other_agents_future_positions', 'all_other_agents_future_yaws', 'all_other_agents_future_availability', 'all_other_agents_types', 'all_other_agents_extents', 'all_other_agents_history_extents', 'scene_index', 'track_id'])\n"
     ]
    }
   ],
   "source": [
    "print(type(obs))\n",
    "print(obs.keys())\n",
    "print(obs[\"agents\"].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from tbsim.configs.scene_edit_config import SceneEditingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args & configs\n",
    "cfg = SceneEditingConfig()\n",
    "config_file = '/local-scratch2/lufan/traceMR/configs/eval/orca/target_pos.json'\n",
    "eval_class = 'Diffuser'\n",
    "policy_ckpt_dir = '/local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed'\n",
    "policy_ckpt_key = 'iter40000'\n",
    "results_root_dir = '/local-scratch2/lufan/traceMR/out/orca_mixed_out'\n",
    "num_scenes_per_batch = 1\n",
    "render = False\n",
    "render_img = True\n",
    "render_size = 400\n",
    "render_px_per_m = 12.0\n",
    "seed = None\n",
    "prefix = None\n",
    "ground_truth = False\n",
    "editing_source = 'heuristic'\n",
    "\n",
    "if config_file is not None:\n",
    "    external_cfg = json.load(open(config_file, \"r\"))\n",
    "    cfg.update(**external_cfg)\n",
    "\n",
    "if eval_class is not None:\n",
    "    cfg.eval_class = eval_class\n",
    "\n",
    "if policy_ckpt_dir is not None:\n",
    "    assert policy_ckpt_key is not None, \"Please specify a key to look for the checkpoint, e.g., 'iter50000'\"\n",
    "    cfg.ckpt.policy.ckpt_dir = policy_ckpt_dir\n",
    "    cfg.ckpt.policy.ckpt_key = policy_ckpt_key\n",
    "\n",
    "if num_scenes_per_batch is not None:\n",
    "    cfg.num_scenes_per_batch = num_scenes_per_batch\n",
    "\n",
    "if cfg.name is None:\n",
    "    cfg.name = cfg.eval_class\n",
    "\n",
    "if prefix is not None:\n",
    "    cfg.name = prefix + cfg.name\n",
    "\n",
    "if seed is not None:\n",
    "    cfg.seed = seed\n",
    "if results_root_dir is not None:\n",
    "    cfg.results_dir = os.path.join(results_root_dir, cfg.name)\n",
    "else:\n",
    "    cfg.results_dir = os.path.join(cfg.results_dir, cfg.name)\n",
    "assert cfg.env == \"trajdata\", \"trajdata is the only supported environment\"\n",
    "if editing_source is not None:\n",
    "    cfg.edits.editing_source = editing_source\n",
    "if not isinstance(cfg.edits.editing_source, list):\n",
    "    cfg.edits.editing_source = [cfg.edits.editing_source]\n",
    "\n",
    "cfg.experience_hdf5_path = os.path.join(cfg.results_dir, \"data.hdf5\")\n",
    "\n",
    "for k in cfg[cfg.env]:  # copy env-specific config to the global-level\n",
    "    cfg[k] = cfg[cfg.env][k]\n",
    "cfg.pop(\"trajdata\")\n",
    "\n",
    "render_cfg = {\n",
    "    'size' : render_size,\n",
    "    'px_per_m' : render_px_per_m,\n",
    "}\n",
    "\n",
    "cfg.lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Env & Basic setup\n",
    "commonly used config:\n",
    "\"n_step_action\": 50,\n",
    "\"num_simulation_steps\": 50,\n",
    "\"skip_first_n\": 0,\n",
    "\"num_sim_per_scene\": 1\n",
    "eval_scences: [0, ... , 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cfg = cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results to /local-scratch2/lufan/traceMR/out/orca_mixed_out/orca_map_open_loop_target_pos\n"
     ]
    }
   ],
   "source": [
    "# Basic Setup\n",
    "save_cfg = True\n",
    "data_to_disk = True\n",
    "render_to_video = False\n",
    "render_to_img = True\n",
    "render_cfg = {'size': 400, 'px_per_m': 12.0}\n",
    "use_gt = False\n",
    "\n",
    "from tbsim.utils.trajdata_utils import set_global_trajdata_batch_env\n",
    "set_global_trajdata_batch_env(eval_cfg.trajdata_source_test[0])\n",
    "# for reproducibility, fix seed\n",
    "np.random.seed(eval_cfg.seed)\n",
    "random.seed(eval_cfg.seed)\n",
    "torch.manual_seed(eval_cfg.seed)\n",
    "torch.cuda.manual_seed(eval_cfg.seed)\n",
    "# basic setup\n",
    "print('saving results to {}'.format(eval_cfg.results_dir))\n",
    "os.makedirs(eval_cfg.results_dir, exist_ok=True)\n",
    "if render_to_video:\n",
    "    os.makedirs(os.path.join(eval_cfg.results_dir, \"videos/\"), exist_ok=True)\n",
    "if render_to_video or render_to_img:\n",
    "    os.makedirs(os.path.join(eval_cfg.results_dir, \"viz/\"), exist_ok=True)\n",
    "if save_cfg:\n",
    "    json.dump(eval_cfg, open(os.path.join(eval_cfg.results_dir, \"config.json\"), \"w+\"))\n",
    "if data_to_disk and os.path.exists(eval_cfg.experience_hdf5_path):\n",
    "    os.remove(eval_cfg.experience_hdf5_path)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed/iter40000.ckpt\n",
      "Config path: /local-scratch2/lufan/traceMR/ckpt/trace/orca_mixed/config.json\n",
      "DIFFUSER: Dropping map input conditioning with p = 0.100000 during training...\n",
      "DIFFUSER: Dropping neighbor traj input conditioning with p = 0.100000 during training...\n",
      "[ models/temporal ] Channel dimensions: [(38, 64), (64, 128), (128, 256)]\n",
      "DIFFUSER: using EMA... val and get_action will use ema model\n"
     ]
    }
   ],
   "source": [
    "# create policy and rollout wrapper\n",
    "policy_composers = importlib.import_module(\"tbsim.evaluation.policy_composers\")\n",
    "composer_class = getattr(policy_composers, eval_cfg.eval_class)\n",
    "composer = composer_class(eval_cfg, device)\n",
    "policy, exp_config = composer.get_policy()\n",
    "policy_model = policy.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determines cfg for rasterizing agents\n",
    "set_global_trajdata_batch_raster_cfg(exp_config.env.rasterizer)\n",
    "\n",
    "# control the full scene with same policy\n",
    "from tbsim.policies.wrappers import RolloutWrapper\n",
    "rollout_policy = RolloutWrapper(agents_policy=policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EnvUnifiedBuilder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create env\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m env_builder \u001b[38;5;241m=\u001b[39m \u001b[43mEnvUnifiedBuilder\u001b[49m(eval_config\u001b[38;5;241m=\u001b[39meval_cfg, exp_config\u001b[38;5;241m=\u001b[39mexp_config, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m env_builder\u001b[38;5;241m.\u001b[39mget_env()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EnvUnifiedBuilder' is not defined"
     ]
    }
   ],
   "source": [
    "# create env\n",
    "env_builder = EnvUnifiedBuilder(eval_config=eval_cfg, exp_config=exp_config, device=device)\n",
    "env = env_builder.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up heuristic guidance config\n",
    "heuristic_config = None\n",
    "if \"heuristic\" in eval_cfg.edits.editing_source:\n",
    "    if eval_cfg.edits.heuristic_config is not None:\n",
    "        heuristic_config = eval_cfg.edits.heuristic_config\n",
    "    else:\n",
    "        heuristic_config = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#render related\n",
    "render_rasterizer = None\n",
    "if render_to_video or render_to_img:\n",
    "    from tbsim.utils.viz_utils import get_trajdata_renderer\n",
    "    # initialize rasterizer once for all scenes\n",
    "    render_rasterizer = get_trajdata_renderer(eval_cfg.trajdata_source_test,\n",
    "                                                eval_cfg.trajdata_data_dirs,\n",
    "                                                raster_size=render_cfg['size'],\n",
    "                                                px_per_m=render_cfg['px_per_m'],\n",
    "                                                rebuild_maps=False,\n",
    "                                                cache_location=eval_cfg.trajdata_cache_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_scenes_per_batch: 1\n",
      "[0]\n",
      "exp_config.algo.history_num_frames: 30\n",
      "Starting frames in current scenes:\n",
      "[[31]]\n"
     ]
    }
   ],
   "source": [
    "# scene related preprocess\n",
    "scene_i = 0\n",
    "eval_scenes = eval_cfg.eval_scenes\n",
    "# while scene_i < eval_cfg.num_scenes_to_evaluate\n",
    "print(f'num_scenes_per_batch: {num_scenes_per_batch}')\n",
    "# starting here, it's in the while scene_i < eval_cfg.num_scenes_to_evaluate loop\n",
    "scene_indices = eval_scenes[scene_i: scene_i + eval_cfg.num_scenes_per_batch]\n",
    "scene_i += eval_cfg.num_scenes_per_batch\n",
    "print(scene_indices)\n",
    "\n",
    "# check to make sure all the scenes are valid at starting step\n",
    "scenes_valid = env.reset(scene_indices=scene_indices, start_frame_index=None)\n",
    "scene_indices = [si for si, sval in zip(scene_indices, scenes_valid) if sval]\n",
    "\n",
    "# if requested, split each scene up into multiple simulations\n",
    "print(f'exp_config.algo.history_num_frames: {exp_config.algo.history_num_frames}')\n",
    "start_frame_index = [[exp_config.algo.history_num_frames+1]] * len(scene_indices)\n",
    "\n",
    "# num_sim_per_scene is predefined in the config.json. I think it's 1 for all the agent\n",
    "# how many sims to run for the current batch of scenes\n",
    "print('Starting frames in current scenes:')\n",
    "print(start_frame_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during each sim in the scene\n",
    "# for ei in range(eval_cfg.num_sim_per_scene) -- it's 1 for all scene so we just skip this\n",
    "ei = 0\n",
    "guidance_config = None # for the current batch of scenes\n",
    "\n",
    "cur_start_frames = [scene_start[ei] for scene_start in start_frame_index]\n",
    "# double check all scenes are valid at the current start step\n",
    "scenes_valid = env.reset(scene_indices=scene_indices, start_frame_index=cur_start_frames)\n",
    "sim_scene_indices = [si for si, sval in zip(scene_indices, scenes_valid) if sval]\n",
    "sim_start_frames = [sframe for sframe, sval in zip(cur_start_frames, scenes_valid) if sval]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'target_pos', 'weight': 30000.0, 'params': {'target_time': 40}}]\n",
      "[[{'name': 'target_pos', 'params': {'target_pos': [[5.590123545755198, -1.174515570518878], [5.76083234951316, -1.2723765352821559], [4.147990116712341, -2.2647575142523846], [5.003380129924496, -1.6954651989966685], [3.8003058803357117, -0.8746731123194786], [0.2061683719248446, 4.200072529769727e-07], [7.353745123561403, -0.5799873588514646], [5.801846577075657, 0.017430045198318034]]}, 'agents': [0, 1, 2, 3, 4, 5, 6, 7], 'weight': 30000.0}]]\n"
     ]
    }
   ],
   "source": [
    "# build heuristic_guidance -- is this where i should make modification?\n",
    "if \"config\" in eval_cfg.edits.editing_source:\n",
    "    guidance_config = eval_cfg.edits.guidance_config\n",
    "if \"heuristic\" in eval_cfg.edits.editing_source:\n",
    "    # build heuristic guidance configs for these scenes\n",
    "    from tbsim.utils.scene_edit_utils import compute_heuristic_guidance, merge_guidance_configs\n",
    "    heuristic_guidance_cfg = compute_heuristic_guidance(heuristic_config,\n",
    "                                                        env,\n",
    "                                                        sim_scene_indices,\n",
    "                                                        sim_start_frames)\n",
    "print(heuristic_config)\n",
    "print(heuristic_guidance_cfg)\n",
    "\n",
    "# check if the guidance is available\n",
    "if len(heuristic_config) > 0:\n",
    "    valid_scene_inds = []\n",
    "    for sci, sc_cfg in enumerate(heuristic_guidance_cfg):\n",
    "        if len(sc_cfg) > 0:\n",
    "            valid_scene_inds.append(sci)\n",
    "    # collect only valid scenes under the given heuristic config\n",
    "    heuristic_guidance_cfg = [heuristic_guidance_cfg[vi] for vi in valid_scene_inds]\n",
    "    sim_scene_indices = [sim_scene_indices[vi] for vi in valid_scene_inds]\n",
    "    sim_start_frames = [sim_start_frames[vi] for vi in valid_scene_inds]\n",
    "    # skip if no valid\n",
    "# add to the current guidance config\n",
    "guidance_config = merge_guidance_configs(guidance_config, heuristic_guidance_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guided_rollout\n",
    "stats, info = guided_rollout( \\\n",
    "    env, \\\n",
    "    rollout_policy, \\\n",
    "    policy_model, \\\n",
    "    n_step_action=eval_cfg.n_step_action, \\\n",
    "    guidance_config=guidance_config, \\\n",
    "    scene_indices=sim_scene_indices, \\\n",
    "    obs_to_torch=True, \\\n",
    "    horizon=eval_cfg.num_simulation_steps, \\\n",
    "    use_gt=use_gt, \\\n",
    "    start_frames=sim_start_frames, \\\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "obs_to_torch = True\n",
    "policy = rollout_policy\n",
    "from tbsim.envs.base import BatchedEnv\n",
    "import tbsim.utils.tensor_utils as TensorUtils\n",
    "\n",
    "stats = {}\n",
    "info = {}\n",
    "is_batched_env = isinstance(env, BatchedEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating test-time guidance with configs:\n",
      "[[{'name': 'target_pos', 'params': {'target_pos': [[5.590123545755198, -1.174515570518878], [5.76083234951316, -1.2723765352821559], [4.147990116712341, -2.2647575142523846], [5.003380129924496, -1.6954651989966685], [3.8003058803357117, -0.8746731123194786], [0.2061683719248446, 4.200072529769727e-07], [7.353745123561403, -0.5799873588514646], [5.801846577075657, 0.017430045198318034]]}, 'agents': [0, 1, 2, 3, 4, 5, 6, 7], 'weight': 30000.0}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup guidance and associated metrics\n",
    "added_metrics = []\n",
    "if guidance_config is not None:\n",
    "    env.reset(scene_indices=sim_scene_indices, start_frame_index=sim_start_frames)\n",
    "    ex_obs = env.get_observation()\n",
    "    if obs_to_torch:\n",
    "        device = policy.device if device is None else device\n",
    "        ex_obs = TensorUtils.to_torch(ex_obs, device=device, ignore_if_unspecified=True)\n",
    "    if not use_gt:\n",
    "        # polciy_model - DiffuserTrafficModel\n",
    "        # policy_model.set_guidance -> cur_policy.set_guidance() -> self.nets[\"policy\"].set_guidance() -> DiffuserModel.\n",
    "        # self.current_guidance = DiffuserGuidance(guidance_config_list, example_batch)\n",
    "        # example_batch= ex_obs['agents'] - obs\n",
    "        # set_guidance is set the GuidanceLoss for each type\n",
    "        policy_model.set_guidance(guidance_config, ex_obs['agents'])\n",
    "    from tbsim.utils.guidance_metrics import guidance_metrics_from_config\n",
    "    # guidance_name_to_metrics\n",
    "    guidance_metrics = guidance_metrics_from_config(guidance_config)\n",
    "    env._metrics.update(guidance_metrics) \n",
    "    added_metrics += guidance_metrics.keys()\n",
    "# metrics are reset here too, so have to run again after adding new metrics\n",
    "env.reset(scene_indices=sim_scene_indices, start_frame_index=sim_start_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start of real rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check if dynamics type is not none\n",
      "> \u001b[0;32m/local-scratch2/lufan/traceMR/tbsim/models/trace.py\u001b[0m(257)\u001b[0;36mget_aux_info\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    255 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'check if dynamics type is not none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    256 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 257 \u001b[0;31m            \u001b[0mcurr_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_utils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdyn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    258 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    259 \u001b[0;31m            \u001b[0mcurr_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/lya108/miniconda3/envs/tracer/lib/python3.8/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608851799/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/localhome/lya108/miniconda3/envs/tracer/lib/python3.8/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608851799/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== GUIDANCE LOSSES ======\n",
      "target_pos_scene_000_00: 0.049981225282\n"
     ]
    }
   ],
   "source": [
    "done = env.is_done()\n",
    "counter = 0\n",
    "# while not done:\n",
    "# let's just try the first step\n",
    "obs = env.get_observation()\n",
    "if obs_to_torch:\n",
    "    device = policy.device if device is None else device\n",
    "    obs_torch = TensorUtils.to_torch(obs, device=device, ignore_if_unspecified=True)\n",
    "else:\n",
    "    obs_torch = obs\n",
    "action = policy.get_action(obs_torch, step_index=counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'agents',\n",
       " 'agents_info',\n",
       " 'ego',\n",
       " 'ego_info',\n",
       " 'from_dict',\n",
       " 'has_agents',\n",
       " 'has_ego',\n",
       " 'to_dict',\n",
       " 'to_numpy',\n",
       " 'transform']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['action_samples', 'diffusion_steps'])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.agents_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 20, 52, 2])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.agents_info['action_samples']['positions'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 20, 52, 1])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.agents_info['action_samples']['yaws'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 52, 101, 6])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.agents_info['diffusion_steps']['traj'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guide_target_pos_s0g0': <tbsim.utils.guidance_metrics.TargetPosGuidance at 0x72726dd02bb0>}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guidance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'target_pos',\n",
       "   'params': {'target_pos': [[5.590123545755198, -1.174515570518878],\n",
       "     [5.76083234951316, -1.2723765352821559],\n",
       "     [4.147990116712341, -2.2647575142523846],\n",
       "     [5.003380129924496, -1.6954651989966685],\n",
       "     [3.8003058803357117, -0.8746731123194786],\n",
       "     [0.2061683719248446, 4.200072529769727e-07],\n",
       "     [7.353745123561403, -0.5799873588514646],\n",
       "     [5.801846577075657, 0.017430045198318034]]},\n",
       "   'agents': [0, 1, 2, 3, 4, 5, 6, 7],\n",
       "   'weight': 30000.0}]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guidance_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_scene = env._current_scenes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats file not found at /local-scratch2/lufan/traceMR//out/orca_mixed_out_tg/orca_map_open_loop_agent_coll/stats.json\n",
      "Stats file not found at /local-scratch2/lufan/traceMR//out/orca_mixed_out_agent_coll_tgmapf_tg_w500/orca_map_open_loop_agent_coll/stats.json\n",
      "Stats file not found at /local-scratch2/lufan/traceMR//out/orca_mixed_out_mapf_tg_w200/orca_map_open_loop_agent_coll/stats.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Read collision statistics from stats.json\n",
    "cfg_l = ['tg', 'agent_coll', 'agent_coll_tg' 'mapf_tg_w500', 'mapf_tg_w200']\n",
    "path_l = [f'orca_mixed_out_{config}' for config in cfg_l]\n",
    "all_coll_rate = {}\n",
    "disk_coll_rate = {}\n",
    "agent_coll_rate = {}\n",
    "\n",
    "for path in path_l:\n",
    "    stats_path = f\"/local-scratch2/lufan/traceMR/out/{path}/orca_map_open_loop_agent_coll/stats.json\"\n",
    "    if os.path.exists(stats_path):\n",
    "        with open(stats_path, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "            \n",
    "        # Extract collision rates\n",
    "        cur_all_coll_rate = stats.get('all_collision_rate_coll_any', None)\n",
    "        cur_disk_coll_rate = stats.get('all_disk_collision_rate_coll_any', None) \n",
    "        cur_agent_coll_rate = stats.get('agents_collision_rate_coll_any', None)\n",
    "        all_coll_rate[path] = cur_all_coll_rate\n",
    "        disk_coll_rate[path] = cur_disk_coll_rate\n",
    "        agent_coll_rate[path] = cur_agent_coll_rate\n",
    "    else:\n",
    "        print(f\"Stats file not found at {stats_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05474999999999999\n",
      "0.13718302127873003\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = '/local-scratch2/lufan/traceMR/out/mapf_w2000/orca_map_open_loop_target_pos_all_coll/stats.json'\n",
    "if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        all_coll_rate = stats.get('all_collision_rate_coll_any', None)\n",
    "        disk_coll_rate = stats.get('all_disk_collision_rate_coll_any', None) \n",
    "        agent_coll_rate = stats.get('agents_collision_rate_coll_any', None)\n",
    "        scene_idx = stats.get('scene_index', None)\n",
    "else:\n",
    "    print(f\"Stats file not found at {path}\")\n",
    "a = np.array(all_coll_rate)\n",
    "mean = a.mean()\n",
    "std = a.std()\n",
    "max = a.max()\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max)\n",
    "idx_worst_3 = np.argsort(a)[-3:]\n",
    "worst_3_values = a[idx_worst_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75 , 0.8  , 0.875])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_3_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_000447_orca_maps\n",
      "scene_000016_orca_maps\n",
      "scene_000682_orca_maps\n"
     ]
    }
   ],
   "source": [
    "for idx in idx_worst_3:\n",
    "    scene = scene_idx[idx]\n",
    "    print(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.162281746031746\n",
      "0.2111314688761148\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# baselines\n",
    "# 1. target pos only\n",
    "path = '/local-scratch2/lufan/traceMR/out/orca_mixed_out/orca_map_open_loop_target_pos/stats.json'\n",
    "if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        all_coll_rate = stats.get('all_collision_rate_coll_any', None)\n",
    "        disk_coll_rate = stats.get('all_disk_collision_rate_coll_any', None) \n",
    "        agent_coll_rate = stats.get('agents_collision_rate_coll_any', None)\n",
    "        scene_idx = stats.get('scene_index', None)\n",
    "else:\n",
    "    print(f\"Stats file not found at {path}\")\n",
    "a = np.array(all_coll_rate)\n",
    "mean = a.mean()\n",
    "std = a.std()\n",
    "max = a.max()\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max)\n",
    "idx_worst_3 = np.argsort(a)[-3:]\n",
    "worst_3_values = a[idx_worst_3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene_000125_orca_maps\n",
      "scene_000682_orca_maps\n",
      "scene_000202_orca_maps\n"
     ]
    }
   ],
   "source": [
    "for idx in idx_worst_3:\n",
    "    scene = scene_idx[idx]\n",
    "    print(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05932936507936508\n",
      "0.14179997390522078\n",
      "0.6666666666666666\n",
      "scene_000447_orca_maps\n",
      "scene_000617_orca_maps\n",
      "scene_000125_orca_maps\n"
     ]
    }
   ],
   "source": [
    "# 2. target pos + agent collision\n",
    "path = '/local-scratch2/lufan/traceMR/out/orca_mixed_out_agent_coll_tg/orca_map_open_loop_agent_coll/stats.json'\n",
    "if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        all_coll_rate = stats.get('all_collision_rate_coll_any', None)\n",
    "        disk_coll_rate = stats.get('all_disk_collision_rate_coll_any', None) \n",
    "        agent_coll_rate = stats.get('agents_collision_rate_coll_any', None)\n",
    "        scene_idx = stats.get('scene_index', None)\n",
    "else:\n",
    "    print(f\"Stats file not found at {path}\")\n",
    "\n",
    "a = np.array(all_coll_rate)\n",
    "mean = a.mean()\n",
    "std = a.std()\n",
    "max = a.max()\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max)\n",
    "idx_worst_3 = np.argsort(a)[-3:]\n",
    "worst_3_values = a[idx_worst_3]\n",
    "\n",
    "for idx in idx_worst_3:\n",
    "    scene = scene_idx[idx]\n",
    "    print(scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn((2, 4))\n",
    "b = torch.randint(low=0, high=4, size=(2,))\n",
    "c = a.gather(1, b.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2446,  0.5071,  0.6448, -0.6639],\n",
       "        [-1.9677, -0.6715,  1.3465,  0.2245]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gather() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (int dim, Tensor index, *, bool sparse_grad)\n * (name dim, Tensor index, *, bool sparse_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: gather() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (int dim, Tensor index, *, bool sparse_grad)\n * (name dim, Tensor index, *, bool sparse_grad)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.66666667])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_3_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28199206349206346\n",
      "0.3025590535987777\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path = '/local-scratch2/lufan/traceMR/out/orca_mixed_out_mapf_tg_w500/orca_map_open_loop_target_pos_all_coll/stats.json'\n",
    "if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        all_coll_rate = stats.get('all_collision_rate_coll_any', None)\n",
    "        disk_coll_rate = stats.get('all_disk_collision_rate_coll_any', None) \n",
    "        agent_coll_rate = stats.get('agents_collision_rate_coll_any', None)\n",
    "else:\n",
    "    print(f\"Stats file not found at {path}\")\n",
    "\n",
    "a = np.array(all_coll_rate)\n",
    "mean = a.mean()\n",
    "std = a.std()\n",
    "max = a.max()\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max)\n",
    "idx_worst_3 = np.argsort(a)[-3:]\n",
    "worst_3_values = a[idx_worst_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_3_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05932936507936508\n",
      "0.14179997390522078\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "a = np.array(all_coll_rate)\n",
    "mean = a.mean()\n",
    "std = a.std()\n",
    "max = a.max()\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_idx = stats.get('scene_index', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scene_000125_orca_maps'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_idx[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scene_000202_orca_maps'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_idx[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24240079365079364\n",
      "0.2951144741135509\n",
      "1.0\n",
      "scene_000662_orca_maps\n",
      "scene_000881_orca_maps\n",
      "scene_000801_orca_maps\n"
     ]
    }
   ],
   "source": [
    "# 2. target pos + agent collision\n",
    "path = '/local-scratch2/lufan/traceMR/out/orca_mixed_out_mapf_tg_w500/orca_map_open_loop_target_pos_all_coll/stats.json'\n",
    "if os.path.exists(path):\n",
    "        with open(path, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        all_coll_rate = stats.get('all_collision_rate_coll_any', None)\n",
    "        disk_coll_rate = stats.get('all_disk_collision_rate_coll_any', None) \n",
    "        agent_coll_rate = stats.get('agents_collision_rate_coll_any', None)\n",
    "        scene_idx = stats.get('scene_index', None)\n",
    "else:\n",
    "    print(f\"Stats file not found at {path}\")\n",
    "\n",
    "a = np.array(all_coll_rate)\n",
    "mean = a.mean()\n",
    "std = a.std()\n",
    "max = a.max()\n",
    "print(mean)\n",
    "print(std)\n",
    "print(max)\n",
    "idx_worst_3 = np.argsort(a)[-3:]\n",
    "worst_3_values = a[idx_worst_3]\n",
    "\n",
    "for idx in idx_worst_3:\n",
    "    scene = scene_idx[idx]\n",
    "    print(scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene scene_000617_orca_maps_31:\n",
      "Positions shape: (4, 50, 2)\n",
      "Yaws shape: (4, 50)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Read trajectory data from h5 file\n",
    "h5_path = '/local-scratch2/lufan/traceMR/out/pre_tp/orca_map_open_loop_target_pos/traj.hdf5'\n",
    "h5_file = h5py.File(h5_path, 'r')\n",
    "\n",
    "# Get all scene indices and their corresponding trajectory data\n",
    "os.makedirs('./out/traj', exist_ok=True)\n",
    "traj_data= {}\n",
    "for scene_key in h5_file.keys():\n",
    "    # if '000013' in scene_key or '00016' in scene_key:\n",
    "    if '000617' in scene_key:\n",
    "        scene_data = h5_file[scene_key]\n",
    "        positions = scene_data['positions'][:]\n",
    "        yaws = scene_data['yaws'][:]\n",
    "        print(f\"Scene {scene_key}:\")\n",
    "        print(f\"Positions shape: {positions.shape}\")\n",
    "        print(f\"Yaws shape: {yaws.shape}\")\n",
    "        print(\"---\")\n",
    "        B = positions.shape[0]\n",
    "        for agent_id in range(B):\n",
    "            cur_positions = positions[agent_id]\n",
    "            cur_yaws = yaws[agent_id]\n",
    "            cur_coord = np.concatenate([cur_positions, cur_yaws[:, None]], axis=1)\n",
    "            traj_data[f'agent_{agent_id}'] = {'coord_dense': cur_coord}\n",
    "with open('./out/traj/traj_data_s617_tp.pkl', 'wb') as f:\n",
    "    pickle.dump(traj_data, f)\n",
    "\n",
    "h5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
